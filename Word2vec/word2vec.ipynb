{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sử dụng Word2vec cho bài toán phân loại sắc thái bình luận"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset \n",
    "dataset trên aivivn.com lưu vào file train.txt\n",
    "bình luận tích cực được đánh label là 0, bình luận tiêu cực được đánh label là 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('train.txt', 'r', encoding='utf8')\n",
    "raw_data = file.read().split('\\n\\ntrain_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lí data và làm sạch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16087\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "label = []\n",
    "for i in raw_data:\n",
    "    tmp = i.split('\\n\"')\n",
    "    data.append(tmp[1][:-3])\n",
    "    label.append(tmp[1][-1])\n",
    "\n",
    "for i in range(len(data)):\n",
    "    for char in data[i]:\n",
    "        if char in \"?.!\\/;:-,>'<)(><^\\n\" or char == '\"':\n",
    "            data[i] = data[i].replace(char, ' ')\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ví dụ về data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-tích cực:\n",
      "Dung dc sp tot cam on  shop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời\n",
      " Chất lượng sản phẩm tuyệt vời   Son mịn nhưng khi đánh lên không như màu trên ảnh\n",
      " Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất\n",
      " Chất lượng sản phẩm tuyệt vời có điều không cứng cáp với không cố định dáng nói chung đẹp hợp túi tiền\n",
      "Đã nhận đc hàng rất nhanh mới đặt buổi tối mà trưa mai là có rồi =}} Đóng gói sản phẩm rất đẹp và chắc chắn Shop phục vụ rất tốt\n",
      "Hàng ship nhanh  chất lượng tốt  tư vấn nhiệt tình ship rất đung size sẽ ủng hộ shop nhìu ❤️\n",
      "\n",
      "-tiêu cực:\n",
      "    Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng  tại sao họ lại phải thức dậy vào thời khắc đấy  sau đó là cả một câu chuyện ra sao  Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn  Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có  BUồn   \n",
      "Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý    \n",
      "Các siêu phẩm thấy cấu hình toàn tựa tựa nhau  Ko còn sự đột phá lớn nữa  Chỉ là nâng cấp  Khác nhau về kiểu dáng  Htc này vs giá trên thật lòng khó cạnh tranh mạnh vs siêu phẩm khác  chỉ dành cho fan của họ thôi \n",
      "Đồng hồ đẹp nhưng 1 cái đứt dây  1 cái k chạy  mua ve phải sửa\n"
     ]
    }
   ],
   "source": [
    "print('-tích cực:')\n",
    "for i in range(10):\n",
    "    if (label[i]=='0'):\n",
    "        print(data[i])\n",
    "print('\\n-tiêu cực:')\n",
    "for i in range(10):\n",
    "    if (label[i]=='1'):\n",
    "        print(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2784312, 3747540)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = []\n",
    "for i in data:\n",
    "    train_data.append(i.split(' '))\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "n_embed = 50 # số chiều của vector sau embbed\n",
    "window_size = 5 # độ dài của bộ sampling\n",
    "\n",
    "model = Word2Vec(train_data, size=n_embed, window=window_size, min_count=1, workers=4, sg=1)\n",
    "\n",
    "model.train(train_data,total_examples=10,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kết quả sau embed của 1 từ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1448618   0.51838213  0.3308078  -0.14750409 -0.22085455 -0.19232313\n",
      "  0.5155055  -0.02643239 -0.18811989 -0.43908268  0.20672658  0.47946337\n",
      "  0.5447136   0.57442576 -0.12181655  0.06245703 -0.34556454 -0.0228148\n",
      " -0.51284266 -0.05451098  0.5876079   0.18916403 -0.33622518  0.8271039\n",
      "  0.49765903  0.15531686  0.24938414  0.13058099  0.32331318 -0.67292506\n",
      " -0.73927826 -0.6644801   0.4288348  -0.45744026 -0.18152225  0.15091918\n",
      "  0.3027491  -0.69305605  0.3426907   0.22803727 -0.39850727  1.1467892\n",
      "  0.02738135 -0.03365581  0.20032531  0.27154052  0.95228785 -0.43982536\n",
      "  0.16039866 -0.71171546]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv['hay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ta còn có thể tìm các từ có mối quan hệ gần với từ đã cho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "similar:tốt\n",
      "('tốt\\xa0', 0.9214968085289001)\n",
      "('\\xa0Shop', 0.8839919567108154)\n",
      "('chă´c', 0.8833966851234436)\n",
      "('\\xa0Rất', 0.8829761147499084)\n",
      "('tiền\\xa0', 0.8815391063690186)\n",
      "('👍', 0.8753457069396973)\n",
      "('Tốt', 0.8745885491371155)\n",
      "('5*\\xa0', 0.872832179069519)\n",
      "('kém\\xa0', 0.868877112865448)\n",
      "('good', 0.8682408928871155)\n",
      "\n",
      "similar:tuyệt\n",
      "('tuyệt\\xa0', 0.8748323917388916)\n",
      "('vời', 0.8629848957061768)\n",
      "('vời\\xa0', 0.8610243797302246)\n",
      "('\\xa0Đóng', 0.8593795299530029)\n",
      "('vờI', 0.8511833548545837)\n",
      "('vờiđóng', 0.8469150066375732)\n",
      "('nước\\xa0', 0.8444494605064392)\n",
      "('chắnsản', 0.8440694212913513)\n",
      "('vờ', 0.8439413905143738)\n",
      "('phhẩm', 0.84212327003479)\n",
      "\n",
      "similar:hay\n",
      "('lẽ', 0.8514580726623535)\n",
      "('Trung', 0.8501659035682678)\n",
      "('Truyện', 0.8485184907913208)\n",
      "('ép', 0.8395031690597534)\n",
      "('quen', 0.8351317048072815)\n",
      "('tản', 0.8342130184173584)\n",
      "('hóa', 0.8306823372840881)\n",
      "('dở', 0.8297426104545593)\n",
      "('riêng', 0.8261379599571228)\n",
      "('Vì', 0.8254278898239136)\n",
      "\n",
      "similar:chất\n",
      "('Chất', 0.7858647108078003)\n",
      "('chât', 0.7522464990615845)\n",
      "('phảm', 0.7308402061462402)\n",
      "('Độ', 0.7302854061126709)\n",
      "('\\xa0Chất', 0.728498637676239)\n",
      "('Tốt', 0.7187888026237488)\n",
      "('đ', 0.7131586670875549)\n",
      "('Sài', 0.7121371030807495)\n",
      "('dữ', 0.7111973166465759)\n",
      "('cải', 0.7110410332679749)\n",
      "\n",
      "similar:không\n",
      "('Không', 0.8415406346321106)\n",
      "('thức', 0.8137040734291077)\n",
      "('Kg', 0.7932605743408203)\n",
      "('Cứ', 0.7878126502037048)\n",
      "('Ko', 0.7877475619316101)\n",
      "('quản', 0.78095942735672)\n",
      "('Chả', 0.7796515822410583)\n",
      "('miễn', 0.778290867805481)\n",
      "('hại', 0.7736963629722595)\n",
      "('chỉnh', 0.7698482871055603)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\python36\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "example = ['tốt', 'tuyệt', 'hay', 'chất', 'không']\n",
    "for i in example:\n",
    "    print('\\nsimilar:'+i)\n",
    "    for word in model.similar_by_word(i):\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Sau khi các từ đã được biểu diễn dưới dạng vector thì có thể tiến hành training bằng bất cứ model nào\n",
    "ví dụ sử dụng SVM để phân loại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_vec = np.zeros([len(train_data),50])\n",
    "for i in range(len(train_data)):\n",
    "    for j in train_data[i]:\n",
    "        data_vec[i]+=np.array(model.wv[j])\n",
    "    data_vec[i]/=len(train_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(data_vec[:10000], label[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.852144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"acc: %f\"  %accuracy_score(model.predict(data_vec[10000:]),label[10000:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Thời gian giao hàng rất nhanh Mình rất hài lòng\n",
      "tích cực\n",
      "\n",
      "K dc muoc mà lấm hơi chậm\n",
      "tiêu cực\n",
      "\n",
      "Giầy đẹp hơn hình đấy shop \n",
      "tích cực\n",
      "\n",
      "ko hài lòng giá thì cao đã đặt thì phải mua ko mua thấy có lỗi với giao quần rất xấu\n",
      "tiêu cực\n",
      "\n",
      "Chưa đeo nên k biết có bền k \n",
      "tiêu cực\n",
      "\n",
      "Giao thiếu 1 đôi  Nhắn tin hỏi không trả lời    \n",
      "tiêu cực\n",
      "\n",
      "Mua 4 cái ki có thước ngắm shop đã liên hệ để gửi thước ngắm nhưng chưa nhận đc  Chất lượng sản phẩm tốt\n",
      "tiêu cực\n",
      "\n",
      "Đẹp lắm ạ  Shop phục vụ rất tốt\n",
      "tích cực\n",
      "\n",
      "Hàng rất đẹp chắc chắn \n",
      "tích cực\n",
      "\n",
      "sóng khoẻ mạng căng  ngày 3g đủ sài     \n",
      "tiêu cực\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    id = np.random.randint(10000,len(train_data))\n",
    "    print(data[id])\n",
    "    if (model.predict([data_vec[id]])=='0'):\n",
    "        print('tích cực\\n')\n",
    "    else:\n",
    "        print('tiêu cực\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
